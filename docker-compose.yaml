services:
  backend:
    image: cat-backend
    restart: unless-stopped
    ports:
      # external_port:internal_port
      # HTTP API
      - "80:8000"
    env_file:
      - app.env
      - .env
    # Start after these services
    depends_on:
      - pg

  spider:
    image: cat-spider
    restart: no
    # Start after these services
    depends_on:
      - pg
      - weaviate
      - ollama
    env_file:
      - app.env
      - .env
    volumes:
      - "${DEPLOY_DIR:-.}/catsearch/download:/opt/catsearch/download"

  weaviate:
    command: --host 0.0.0.0 --port 8080 --scheme http
    image: cr.weaviate.io/semitechnologies/weaviate:1.30.0
    restart: unless-stopped
    depends_on:
      - ollama
    ports:
      # external_port:internal_port
      # HTTP API
      - "8080:8080"
      # gRPC
      - "50051:50051"
    volumes:
      - "${DEPLOY_DIR:-.}/catsearch/weaviate:/var/lib/weaviate"
    env_file:
      - .env
    environment:
      # Image Vectorization
      IMAGE_INFERENCE_API: 'http://i2v-neural:8080'
      QUERY_DEFAULTS_LIMIT: 25
      # Where to store persistent data
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'text2vec-ollama'
      # Ollama Integration
      OLLAMA_API_ENDPOINT: 'http://ollama:11434/api/embeddings'
      # ENABLE_MODULES
      #   text2vec-ollama:    for text embeddings using the Ollama LLM backend.
      #   img2vec-neural:     for image embeddings.
      #   generative-ollama:  for generative tasks (e.g., summarization, QA).
      ENABLE_MODULES: 'text2vec-ollama,generative-ollama'
      CLUSTER_HOSTNAME: 'node1'
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'false'
      # Enables API key authentication.
      AUTHENTICATION_APIKEY_ENABLED: 'true'
      # List one or more keys in plaintext separated by commas. Each key corresponds to a specific user identity below.
      AUTHENTICATION_APIKEY_ALLOWED_KEYS: 'Search_the_VK'
      # List one or more user identities, separated by commas. Each identity corresponds to a specific key above.
      AUTHENTICATION_APIKEY_USERS: 'admin'

  ollama:
    image: ollama/ollama
    restart: unless-stopped
    ports:
      # external_port:internal_port
      - "11434:11434"
    env_file:
      - .env
    volumes:
      - "${DEPLOY_DIR:-.}/catsearch/ollama:/root/.ollama"
      # Script entrypoint.sh will pull the models
      - ./ollama/entrypoint.sh:/entrypoint.sh
    entrypoint: ["/bin/bash", "/entrypoint.sh"]
    # For NVIDIA GPU uncomment settings below
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  pg:
    image: "postgres:17"
    restart: unless-stopped
    env_file:
      - .env
    environment:
      PGDATA: /var/lib/postgresql/data/pgdata
      POSTGRES_DB: catsearch
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: Oue$8AriEOdN
    volumes:
      # external_directory:internal_directory
      # volume for postgresql data
      - "${DEPLOY_DIR:-.}/catsearch/pg/pgdata:/var/lib/postgresql/data/pgdata"
      # volume for .dump files
      - ./pg/backups:/docker-entrypoint-initdb.d/backups
      - ./pg/scripts:/docker-entrypoint-initdb.d
    ports:
      # "external_port:internal_port"
      - "5432:5432"

  tg-bot:
    image: tg-bot
    restart: unless-stopped
    env_file:
      - .env
      - app.env
    depends_on:
      - backend

